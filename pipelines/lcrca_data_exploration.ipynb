{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtfs_realtime_utils import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "ROOT = Path(\"../\")\n",
    "ROOT.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtfsrt_filepaths_to_list(dir, date):\n",
    "    date_with_dashes = f\"{date[0:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "    # Create an empty list to store file paths\n",
    "    gtfs_rt_file_paths = []\n",
    "\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            # Get the full path of the file and append it to the list\n",
    "            if file[0:10] == date_with_dashes: #@TODO improve the slice here to a regex match for the date.\n",
    "                full_path = os.path.abspath(os.path.join(root, file))\n",
    "                gtfs_rt_file_paths.append(full_path)\n",
    "    return gtfs_rt_file_paths\n",
    "date='20240916'\n",
    "REALTIME_DATADIR = ROOT / f\"data/gtfs-rt\"\n",
    "gtfsrt_filepaths = gtfsrt_filepaths_to_list(dir=REALTIME_DATADIR, date=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the feed object\n",
    "feed = gtfs_realtime_pb2.FeedMessage()\n",
    "# Add all the entities to a list to iterate through later.\n",
    "entities = entities_to_list(feed, gtfsrt_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_list_to_df(entities):\n",
    "    trip_ids = []\n",
    "    start_times = []\n",
    "    start_dates = []\n",
    "    schedule_relationships = []\n",
    "    route_ids = []\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    bearing = []\n",
    "    stop_sequence = []\n",
    "    status = []\n",
    "    timestamps = []\n",
    "    vehicle_ids = []\n",
    "    for e in entities:\n",
    "        v = e.vehicle\n",
    "        trip_ids.append(v.trip.trip_id)\n",
    "        start_times.append(v.trip.start_time)\n",
    "        start_dates.append(v.trip.start_date)\n",
    "        schedule_relationships.append(v.trip.schedule_relationship)\n",
    "        route_ids.append(v.trip.route_id)\n",
    "        longitude.append(v.position.longitude)\n",
    "        latitude.append(v.position.latitude)\n",
    "        bearing.append(v.position.bearing)\n",
    "        stop_sequence.append(v.current_stop_sequence)\n",
    "        status.append(v.current_status)\n",
    "        timestamps.append(v.timestamp)\n",
    "        vehicle_ids.append(v.vehicle.id)\n",
    "\n",
    "    data = pd.DataFrame({'trip_id': trip_ids, 'start_time': start_times, 'start_date': start_dates, 'schedule_relationship': schedule_relationships, 'route_id': route_ids,\n",
    "                        'latitude': latitude, 'longitude': longitude, 'bearing': bearing, 'stop_sequence': stop_sequence, 'status': status, 'timestamp': timestamps, 'vehicle_id': vehicle_ids})\n",
    "\n",
    "    data['human_time'] = pd.to_datetime(data['timestamp'], unit='s')\n",
    "    data['latitude'] = data['latitude'].round(5)\n",
    "    data['longitude'] = data['longitude'].round(5)\n",
    "\n",
    "    # Sort the data\n",
    "    data.sort_values(by=['vehicle_id', 'timestamp', 'trip_id'], ascending=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = entity_list_to_df(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the timetable\n",
    "region = 'north_west'\n",
    "tt_agencies, tt_routes, tt_trips, tt_stops, tt_stop_times, tt_calendar, tt_calendar_dates = load_full_gtfs(ROOT / f\"18SepGB_GTFS_Timetables_Downloaded/itm_{region}_gtfs.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_timetabled_trips_for_date(trips, calendar, date):\n",
    "    '''Calculate the number of unique trips for a given date using GTFS data loaded into a pandas dataframe'''\n",
    "    int_date = int(date)\n",
    "    str_date = str(date)\n",
    "    assert type(trips) == pd.DataFrame, '\"trips\" is not a dataframe.'\n",
    "    assert type(calendar) == pd.DataFrame, '\"calendar\" is not a dataframe.'\n",
    "    assert 'service_id' in calendar.columns, f\"'service_id' not in {calendar.columns}\"\n",
    "    assert 'trip_id' in trips.columns, f\"'service_id' not in {trips.columns}\"\n",
    "\n",
    "    p = trips.merge(calendar, on='service_id', how='inner')\n",
    "    # Convert to datetime object\n",
    "    date_obj = datetime.fromisoformat(str_date)\n",
    "    # Get the day of the week\n",
    "    day_of_week = date_obj.strftime('%A').lower()\n",
    "    # Select rows that run on that day of the week\n",
    "    p = p[p[day_of_week]==1]\n",
    "    # Select rows where the service date range covers the input date\n",
    "    p = p[(p.start_date <= int_date) & (p.end_date >= int_date)]\n",
    "    # Return the number of unique trip_id for that date of the timetable.\n",
    "    return p\n",
    "\n",
    "def count_unique_trip_id(df):\n",
    "    assert 'trip_id' in df.columns\n",
    "    return len(df.trip_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. How many of the Trip IDs in the North West timetable have at least one stop inside the Liverpool City Region CA boundary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the boundary of LCRCA\n",
    "bndry = gpd.read_file(ROOT / \"data/geojson/LCRCA_May2023_Boundary_EN_BGC.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe of trips that run on input date\n",
    "for date in range(20240915, 20240924):\n",
    "    trips_on_this_date_df = unique_timetabled_trips_for_date(tt_trips, tt_calendar, date=date)\n",
    "    print(\"Date:\", date)\n",
    "    print(f\"Number of unique trips timetabled, {count_unique_trip_id(trips_on_this_date_df)}\")\n",
    "    # Get a list of trip_ids that run on input date\n",
    "    list_of_trip_ids_on_this_date = trips_on_this_date_df.trip_id.unique()\n",
    "    # Use that to filter the stop_times down to only ones on input date\n",
    "    tt_stop_times_this_date = tt_stop_times[tt_stop_times.trip_id.isin(list_of_trip_ids_on_this_date)]\n",
    "\n",
    "    # Get all the stops that are on trips that run on input date\n",
    "    full_stop_info = tt_stops.merge(tt_stop_times_this_date, on='stop_id', how='inner').loc[:, ['trip_id', 'stop_lat', 'stop_lon']]\n",
    "\n",
    "    # Create Point geometries for the stop coordinates.\n",
    "    stop_points = [Point(xy) for xy in zip(full_stop_info['stop_lon'], full_stop_info['stop_lat'])]\n",
    "    # Create a GeoDataFrame of the stops that are stopped at on the input date\n",
    "    points_gdf = gpd.GeoDataFrame(full_stop_info, geometry=stop_points, crs='EPSG:4326')\n",
    "\n",
    "    # Perform spatial join with the boundary based on whether each stop is within the boundary or not.\n",
    "    joined_gdf = gpd.sjoin(points_gdf, bndry, how=\"left\", predicate=\"within\")\n",
    "\n",
    "    # Filter the geodf to only stops that are within the boundary (right index is not NA)\n",
    "    points_inside_bndry = joined_gdf[joined_gdf.index_right.notna()]\n",
    "\n",
    "    # Get a list of the unique Trip IDs that have at least one stop in the boundary\n",
    "    list_of_trips_in_boundary = points_inside_bndry.trip_id.unique()\n",
    "\n",
    "    # Determine how many of the above there are.\n",
    "    number_in_boundary = len(list_of_trips_in_boundary)\n",
    "\n",
    "    # How many of the trip_ids that have at least 1 stop inside the boundary are in the live data?\n",
    "    number_in_boundary_and_live_data = len(data[data.trip_id.isin(list_of_trips_in_boundary)].trip_id.unique())\n",
    "\n",
    "    print(f\"Number of unique trip_ids with at least one stop in Liverpool City Region CA:\", number_in_boundary)\n",
    "    print(f\"Number of those trip_ids that are also in our live data:\", number_in_boundary_and_live_data)\n",
    "    print(f\"Percentage: {round(100*number_in_boundary_and_live_data/number_in_boundary,2)}%\")\n",
    "    print(\"-------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bus-tracking-JZQiYmLK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
