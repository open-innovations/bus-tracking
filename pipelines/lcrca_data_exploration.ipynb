{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point of this notebook is to evaluate good the data is for LCRCA area in terms of coverage compared to the timetable and coverage of individual trips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Loading packages and setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/lukestrange/Code/bus-tracking')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtfs_realtime_utils import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "ROOT = Path(\"../\")\n",
    "ROOT.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the timetables for a specific region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File \"../18SepGB_GTFS_Timetables_Downloaded/itm_north_west_gtfs.zip\" is a zip file. Unzipping and reading...\n"
     ]
    }
   ],
   "source": [
    "# Load the timetable\n",
    "region = 'north_west'\n",
    "date = '20240915'\n",
    "tt_agencies, tt_routes, tt_trips, tt_stops, tt_stop_times, tt_calendar, tt_calendar_dates = load_full_gtfs(ROOT / f\"18SepGB_GTFS_Timetables_Downloaded/itm_{region}_gtfs.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_timetabled_trips_for_date(trips, calendar, date):\n",
    "    '''Calculate the number of unique trips for a given date using GTFS data loaded into a pandas dataframe'''\n",
    "    int_date = int(date)\n",
    "    str_date = str(date)\n",
    "    assert type(trips) == pd.DataFrame, '\"trips\" is not a dataframe.'\n",
    "    assert type(calendar) == pd.DataFrame, '\"calendar\" is not a dataframe.'\n",
    "    assert 'service_id' in calendar.columns, f\"'service_id' not in {calendar.columns}\"\n",
    "    assert 'trip_id' in trips.columns, f\"'service_id' not in {trips.columns}\"\n",
    "\n",
    "    p = trips.merge(calendar, on='service_id', how='inner')\n",
    "    # Convert to datetime object\n",
    "    date_obj = datetime.fromisoformat(str_date)\n",
    "    # Get the day of the week\n",
    "    day_of_week = date_obj.strftime('%A').lower()\n",
    "    # Select rows that run on that day of the week\n",
    "    p = p[p[day_of_week]==1]\n",
    "    # Select rows where the service date range covers the input date\n",
    "    p = p[(p.start_date <= int_date) & (p.end_date >= int_date)]\n",
    "    # Return the number of unique trip_id for that date of the timetable.\n",
    "    return p\n",
    "\n",
    "def count_unique_trip_id(df):\n",
    "    assert 'trip_id' in df.columns\n",
    "    return len(df.trip_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_unique_trip_id(unique_timetabled_trips_for_date(tt_trips, tt_calendar, date=date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all bus data for England (excl. London) on a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_data = pd.read_csv(ROOT / f\"data/gtfs-rt/csv/{date}.csv\",low_memory=False)\n",
    "rt_data['trip_id'] = rt_data['trip_id'].fillna('')\n",
    "# rt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovering trip_ids that drop out and reappear for the same vehicle_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many trip_ids can we recover\n",
    "trip_id_list = rt_data.trip_id.to_list()\n",
    "filled_dropouts = fill_trip_ids(trip_id_list)\n",
    "before_filling_gaps = fraction_with_trip_id(trip_id_list)\n",
    "after_filling_gaps = fraction_with_trip_id(filled_dropouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many of the Trip IDs in the North West timetable have at least one stop inside the Liverpool City Region CA boundary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the boundary of LCRCA\n",
    "bndry = gpd.read_file(ROOT / \"data/geojson/LCRCA_May2023_Boundary_EN_BGC.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cancelled_buses(data):\n",
    "    subset = data[data.schedule_relationship != 0]\n",
    "    return len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe of trips that run on input date\n",
    "trips_on_this_date_df = unique_timetabled_trips_for_date(tt_trips, tt_calendar, date=date)\n",
    "\n",
    "# Get a list of trip_ids that run on input date\n",
    "list_of_trip_ids_on_this_date = trips_on_this_date_df.trip_id.unique()\n",
    "# Use that to filter the stop_times down to only ones on input date\n",
    "tt_stop_times_this_date = tt_stop_times[tt_stop_times.trip_id.isin(list_of_trip_ids_on_this_date)]\n",
    "\n",
    "# Get all the stops that are on trips that run on input date\n",
    "full_stop_info = tt_stops.merge(tt_stop_times_this_date, on='stop_id', how='inner').loc[:, ['trip_id', 'stop_lat', 'stop_lon']]\n",
    "\n",
    "# Create Point geometries for the stop coordinates.\n",
    "stop_points = [Point(xy) for xy in zip(full_stop_info['stop_lon'], full_stop_info['stop_lat'])]\n",
    "\n",
    "# Create a GeoDataFrame of the stops that are stopped at on the input date\n",
    "points_gdf = gpd.GeoDataFrame(full_stop_info, geometry=stop_points, crs='EPSG:4326')\n",
    "\n",
    "# Perform spatial join with the boundary based on whether each stop is within the boundary or not.\n",
    "joined_gdf = gpd.sjoin(points_gdf, bndry, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Filter the geo-df to only stops that are within the boundary (right index is not NA)\n",
    "points_inside_bndry = joined_gdf[joined_gdf.index_right.notna()]\n",
    "\n",
    "# Get a list of the unique Trip IDs that have at least one stop in the boundary\n",
    "list_of_trips_in_boundary = points_inside_bndry.trip_id.unique()\n",
    "\n",
    "# Determine how many of the above there are.\n",
    "number_in_boundary = len(list_of_trips_in_boundary)\n",
    "\n",
    "# How many of the trip_ids that have at least 1 stop inside the boundary are in the live data?\n",
    "real_data_in_boundary = rt_data[rt_data.trip_id.isin(list_of_trips_in_boundary)]\n",
    "\n",
    "number_in_boundary_and_live_data = len(real_data_in_boundary.trip_id.unique())\n",
    "\n",
    "# Count the occurrences of each trip_id\n",
    "trip_counts = real_data_in_boundary['trip_id'].value_counts()\n",
    "\n",
    "# Filter to get trip_ids that appear at least 10 times\n",
    "filtered_trip_ids = trip_counts[trip_counts >= 10]\n",
    "\n",
    "# Total number of unique trip_ids\n",
    "total_unique_trips = real_data_in_boundary['trip_id'].nunique()\n",
    "\n",
    "# Calculate the fraction\n",
    "fraction = len(filtered_trip_ids) / total_unique_trips\n",
    "with open(ROOT / f\"data/evaluate/{date}.txt\", 'w') as f:\n",
    "    f.writelines(f\"Date: {date}\")\n",
    "    f.writelines(\"\\n--BODS (all England)--\")\n",
    "    f.writelines(f\"\\nPercentage of de-duplicated BODS data with trip_id(s) before filling gaps: {round(before_filling_gaps,2)}%\")\n",
    "    f.writelines(f\"\\nPercentage of de-duplicated BODS data with trip_id(s) after filling gaps: {round(after_filling_gaps, 2)}%\")\n",
    "    f.writelines(f\"\\nPercentage of de-duplicated BODS data without trip_id: {round(100-after_filling_gaps,2)}%\")\n",
    "    f.writelines(f\"\\nPercentage of de-duplicated BODS data we recovered a trip_id: {round(after_filling_gaps - before_filling_gaps, 2)}%\")\n",
    "    f.writelines(\"\\n\\n--LCRCA ONLY--\")\n",
    "    # f.writelines(f\"\\nNumber of unique trips timetabled in Liverpool City Region on {date}: {count_unique_trip_id(trips_on_this_date_df)}\")\n",
    "    # f.writelines(f\"\\nNumber of unique trip_ids with at least one stop in Liverpool City Region CA: {number_in_boundary}\")\n",
    "    # f.writelines(f\"\\nNumber of those trip_ids that are also in our live data: {number_in_boundary_and_live_data}\")\n",
    "    f.writelines(f\"\\nPercentage of timetabled buses for which we tracked at least 1 data point: {round(100*number_in_boundary_and_live_data/number_in_boundary,2)}%\")\n",
    "    f.writelines(f\"\\nCancelled buses that were in the real data: {count_cancelled_buses(real_data_in_boundary)}\")\n",
    "    f.writelines(\"\\nBuses not tracked because they were cancelled: unknown\")\n",
    "    f.writelines(\"\\nBuses that never appear in BODS, but the buses still ran: unknown\")\n",
    "    f.writelines(f\"\\nPercentage of buses we tracked with trip_ids and at least 10 different locations/times: {round(100*fraction, 2)}\")\n",
    "    f.writelines(\"\\n-------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bus-tracking-JZQiYmLK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
