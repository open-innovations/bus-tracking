{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/lukestrange/Code/bus-tracking')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtfs_realtime_utils import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "ROOT = Path(\"../\")\n",
    "ROOT.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all bus data for England (excl. London) on a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtfsrt_filepaths_to_list(dir, date):\n",
    "    date_with_dashes = f\"{date[0:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "    # Create an empty list to store file paths\n",
    "    gtfs_rt_file_paths = []\n",
    "\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            # Get the full path of the file and append it to the list\n",
    "            if file[0:10] == date_with_dashes: #@TODO improve the slice here to a regex match for the date.\n",
    "                full_path = os.path.abspath(os.path.join(root, file))\n",
    "                gtfs_rt_file_paths.append(full_path)\n",
    "    return gtfs_rt_file_paths\n",
    "\n",
    "def entity_list_to_df(entities, date):\n",
    "    trip_ids = []\n",
    "    start_times = []\n",
    "    start_dates = []\n",
    "    schedule_relationships = []\n",
    "    route_ids = []\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    bearing = []\n",
    "    stop_sequence = []\n",
    "    status = []\n",
    "    timestamps = []\n",
    "    vehicle_ids = []\n",
    "    print(len(entities))\n",
    "    for e in entities:\n",
    "        v = e.vehicle\n",
    "        trip_ids.append(v.trip.trip_id)\n",
    "        start_times.append(v.trip.start_time)\n",
    "        start_dates.append(v.trip.start_date)\n",
    "        schedule_relationships.append(v.trip.schedule_relationship)\n",
    "        route_ids.append(v.trip.route_id)\n",
    "        longitude.append(v.position.longitude)\n",
    "        latitude.append(v.position.latitude)\n",
    "        bearing.append(v.position.bearing)\n",
    "        stop_sequence.append(v.current_stop_sequence)\n",
    "        status.append(v.current_status)\n",
    "        timestamps.append(v.timestamp)\n",
    "        vehicle_ids.append(v.vehicle.id)\n",
    "\n",
    "    data = pd.DataFrame({'trip_id': trip_ids, 'start_time': start_times, 'start_date': start_dates, 'schedule_relationship': schedule_relationships, 'route_id': route_ids,\n",
    "                        'latitude': latitude, 'longitude': longitude, 'bearing': bearing, 'stop_sequence': stop_sequence, 'status': status, 'timestamp': timestamps, 'vehicle_id': vehicle_ids})\n",
    "\n",
    "    # data['human_time'] = pd.to_datetime(data['timestamp'], unit='s')\n",
    "    data['latitude'] = data['latitude'].round(5)\n",
    "    data['longitude'] = data['longitude'].round(5)\n",
    "\n",
    "    # Sort the data\n",
    "    data.sort_values(by=['vehicle_id', 'timestamp', 'trip_id'], ascending=True, inplace=True)\n",
    "    with_duplicates = len(data)\n",
    "    data.drop_duplicates(subset=['longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id'], keep='first', inplace=True) # The first/last here shouldn't matter as one of the duplicate fields is timestamp. So these are data points that are for the same point in time too.\n",
    "    without_duplicates = len(data)\n",
    "    fraction_duplicated = 1 - without_duplicates/with_duplicates\n",
    "    print(f\"Fraction of data for {date} that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':{fraction_duplicated}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for 20240915\n",
      "28584494\n",
      "Fraction of data for 20240915 that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':0.8568668383634848\n",
      "Created dataframe for 20240915\n",
      "Finished writing 20240915\n",
      "Loaded data for 20240916\n",
      "25628104\n",
      "Fraction of data for 20240916 that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':0.6518878649782286\n",
      "Created dataframe for 20240916\n",
      "Finished writing 20240916\n",
      "Loaded data for 20240917\n",
      "28830261\n",
      "Fraction of data for 20240917 that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':0.62329643841934\n",
      "Created dataframe for 20240917\n",
      "Finished writing 20240917\n",
      "Loaded data for 20240918\n",
      "28835781\n",
      "Fraction of data for 20240918 that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':0.6373314806351178\n",
      "Created dataframe for 20240918\n",
      "Finished writing 20240918\n",
      "Loaded data for 20240919\n",
      "29227725\n",
      "Fraction of data for 20240919 that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':0.6247131790106826\n",
      "Created dataframe for 20240919\n",
      "Finished writing 20240919\n",
      "Loaded data for 20240920\n",
      "29412638\n",
      "Fraction of data for 20240920 that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':0.628073517241126\n",
      "Created dataframe for 20240920\n",
      "Finished writing 20240920\n",
      "Loaded data for 20240921\n",
      "29509351\n",
      "Fraction of data for 20240921 that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':0.683032676659002\n",
      "Created dataframe for 20240921\n",
      "Finished writing 20240921\n",
      "Loaded data for 20240922\n",
      "29604824\n",
      "Fraction of data for 20240922 that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':0.8489898470600602\n",
      "Created dataframe for 20240922\n",
      "Finished writing 20240922\n",
      "Loaded data for 20240923\n",
      "29353157\n",
      "Fraction of data for 20240923 that was duplictaed in 'longitude', 'latitude', 'timestamp', 'vehicle_id', 'trip_id':0.6309005876267415\n",
      "Created dataframe for 20240923\n",
      "Finished writing 20240923\n"
     ]
    }
   ],
   "source": [
    "for date in range(20240915, 20240924):\n",
    "    data = None\n",
    "    gtfsrt_filepaths = None\n",
    "    entities = None\n",
    "\n",
    "    date = str(date)\n",
    "    REALTIME_DATADIR = ROOT / f\"data/gtfs-rt\"\n",
    "    gtfsrt_filepaths = gtfsrt_filepaths_to_list(dir=REALTIME_DATADIR, date=date)\n",
    "    \n",
    "    # Initialise the feed object\n",
    "    feed = gtfs_realtime_pb2.FeedMessage()\n",
    "    # Add all the entities (bus location objects) to a list to iterate through later.\n",
    "    entities = entities_to_list(feed, gtfsrt_filepaths)\n",
    "    print(f\"Loaded data for {date}\")\n",
    "    # Add data to dataframe and sort\n",
    "    data = entity_list_to_df(entities, date)\n",
    "\n",
    "    print(f\"Created dataframe for {date}\")\n",
    "\n",
    "    data.to_csv(ROOT / f\"data/gtfs-rt/csv/{date}.csv\", index=False)\n",
    "    print(f'Finished writing {date}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bus-tracking-JZQiYmLK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
