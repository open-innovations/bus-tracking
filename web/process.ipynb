{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "os.chdir(\"../\")\n",
    "from pathlib import Path\n",
    "from pipelines.utils import *\n",
    "ROOT = Path(os.getcwd())\n",
    "ROOT.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the lookup data\n",
    "with open(ROOT / \"web/bustimes.org.json\") as f:\n",
    "    route_detail_lookup = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'north_west'\n",
    "rgncd = 'TLD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files(path):\n",
    "    files = glob.glob(os.path.abspath(path))\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_files(ROOT / f\"web/{rgncd}/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GTFSRT data\n",
    "dates = [f'202409{i}' for i in range(15, 24)]\n",
    "date_strs = [make_date_with_dashes(date) for date in dates]\n",
    "gtfsrt_data = [[load_full_gtfs(ROOT / f\"data/real-interpolated/{region}_{date}.gtfs.zip\", ['shapes.txt']), date_str] for date, date_str in zip(dates, date_strs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the timetable\n",
    "tt_agencies, tt_routes, tt_trips, tt_stops, tt_stop_times, tt_calendar, tt_calendar_dates = load_full_gtfs(ROOT / f\"18SepGB_GTFS_Timetables_Downloaded/itm_{region}_gtfs.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glue all the realtime data together\n",
    "def glue_data(data, item, subset=None, drop_duplicates=True):\n",
    "    ''''''\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if not result.empty:\n",
    "            result = pd.concat([result, data[i][0][item]])\n",
    "\n",
    "            if item==4:\n",
    "                result['date_str'] = result['date_str'].fillna(data[i][1])\n",
    "                \n",
    "        else:\n",
    "            result = data[i][0][item]\n",
    "            if item==4:\n",
    "                result['date_str'] = data[i][1]\n",
    "            \n",
    "    if drop_duplicates:\n",
    "        result.drop_duplicates(subset, inplace=True, keep='first')\n",
    "\n",
    "    return result\n",
    "\n",
    "all_agency = glue_data(gtfsrt_data, 0, drop_duplicates=True, subset='agency_id')\n",
    "all_routes = glue_data(gtfsrt_data, 1, drop_duplicates=True, subset='route_id')\n",
    "all_trips = glue_data(gtfsrt_data, 2, drop_duplicates=False)\n",
    "all_stop_times = glue_data(gtfsrt_data, 4, drop_duplicates=True, subset=['trip_id', 'stop_id', 'stop_sequence', 'date_str'])\n",
    "all_stops = glue_data(gtfsrt_data, 3, drop_duplicates=True, subset='stop_id')\n",
    "all_calendars = glue_data(gtfsrt_data, 5, drop_duplicates=True, subset='service_id')\n",
    "all_shapes = glue_data(gtfsrt_data, 7, drop_duplicates=True, subset=['shape_id', 'shape_pt_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_route_info(lookup:dict, route_short_name:str, agency_noc:str):\n",
    "    \"\"\"\n",
    "    Provide the detailed info for a route given its `route_short_name` and `agency_noc`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lookup: dict\n",
    "        Dictionary containing route info\n",
    "    route_short_name: str\n",
    "        Usually the display name of the service. For example \"13A\".\n",
    "    agency_noc: str \n",
    "        Agency National operator code.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    id: \n",
    "        human-reable unique id of the bus route.\n",
    "    name: \n",
    "        human-readable name of the bus route.\n",
    "    \"\"\"\n",
    "    id = lookup[agency_noc][route_short_name]['id']\n",
    "    name = lookup[agency_noc][route_short_name]['name']\n",
    "    return id, name\n",
    "\n",
    "def get_row_info(row):\n",
    "    route_id = row['route_id']\n",
    "    agency_id = row['agency_id']\n",
    "    route_short_name = row['route_short_name']\n",
    "    agency_noc = row['agency_noc']\n",
    "    agency_name = row['agency_name']\n",
    "    return route_id, route_short_name, agency_id, agency_noc, agency_name\n",
    "\n",
    "def get_route_id(agency_id, route_short_name, routes):\n",
    "    return routes[(routes.agency_id == agency_id) & (routes.route_short_name == route_short_name)].route_id.values[0]\n",
    "\n",
    "def get_trips_on_this_route(route_id:str, trips):\n",
    "    return trips[trips.route_id == route_id][['trip_id', 'trip_headsign', 'shape_id']]\n",
    "\n",
    "def get_unique_values_from_column(data, column_name:str):\n",
    "    return data[column_name].unique()\n",
    "\n",
    "def create_metadata(human_route_name, human_route_id, agency_name, agency_noc, bustimesorg):\n",
    "    return dict({'id': human_route_id, \n",
    "                 'name': human_route_name, \n",
    "                 \"agency_name\": agency_name, \n",
    "                 \"agency_noc\": agency_noc,\n",
    "                 \"bustimesorg\": bustimesorg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes2agency = all_routes.merge(all_agency, on='agency_id', how='inner')\n",
    "all_routes_dict = routes2agency.set_index('route_id').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stop_times = all_stop_times[['trip_id', 'stop_id', 'stop_sequence', 'arrival_time', 'date_str', 'interpolated']]\n",
    "tt_stop_times = tt_stop_times[['trip_id', 'stop_id', 'stop_sequence', 'arrival_time']]\n",
    "all_stop_times = all_stop_times.merge(tt_stop_times, on=['trip_id', 'stop_id', 'stop_sequence'], how='inner', suffixes=('_real', '_timetable'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip2stoptimes = all_stop_times.groupby(['trip_id', 'date_str'])[['arrival_time_real', 'arrival_time_timetable', 'stop_id', 'stop_sequence', 'date_str', 'interpolated']].agg(list).to_dict(orient='index')\n",
    "shape_dict = all_shapes.groupby('shape_id').apply(lambda x: x[['shape_pt_lon', 'shape_pt_lat']].values.round(5).tolist(), include_groups=False).reset_index(name='geometry').set_index('shape_id').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_bearings = get_stop_names_and_bearings(ROOT)[['stop_id', 'Bearing']] \n",
    "stops_dict = all_stops.merge(stop_bearings, on='stop_id', how='inner').set_index('stop_id').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in all_routes_dict.items():\n",
    "    route_id = key\n",
    "    agency_id, route_short_name, agency_noc, agency_name = values['agency_id'], values['route_short_name'], values['agency_noc'], values['agency_name']\n",
    "    # Ensure that route short name is upper case to match with IDs from bustimes.org\n",
    "    route_short_name = route_short_name.upper()\n",
    "    try:\n",
    "        human_route_id, human_route_name = get_detailed_route_info(route_detail_lookup, route_short_name, agency_noc)\n",
    "        bus_times_org = True\n",
    "        \n",
    "    except:\n",
    "        msg = f\"Unable to find route name details via bustimes.org for {route_short_name, agency_noc, agency_name}. Using route_short_name and agency_name/noc instead.\\n\"\n",
    "        with open(ROOT / f'web/{rgncd}-errors.txt', 'a') as f:\n",
    "            f.writelines(msg)\n",
    "        \n",
    "        human_route_id = f\"{route_short_name}-{agency_noc}\"\n",
    "        human_route_name = f\"{route_short_name} - {agency_name}\"\n",
    "        bus_times_org = False\n",
    "    \n",
    "    # Write the metadata to a dictionary\n",
    "    meta = create_metadata(human_route_name, human_route_id, agency_name, agency_noc, bus_times_org)\n",
    "    \n",
    "    trips_on_this_route = get_trips_on_this_route(route_id, all_trips)\n",
    "    unique_trips = get_unique_values_from_column(trips_on_this_route, 'trip_id')\n",
    "    trips = []\n",
    "    # Adding every stop id on this route to a list, so that we can find that set from it later on in the code.\n",
    "    all_stop_ids = []\n",
    "\n",
    "    for trip_id, ds in itertools.product(unique_trips, date_strs):\n",
    "        try:\n",
    "            stop_info = trip2stoptimes[trip_id, ds]\n",
    "        except KeyError:\n",
    "            # print(f'No real time info for trip_id:{trip_id}, route_id:{route_id}, agency_name:{agency_name}, route number: {route_short_name}')\n",
    "            continue\n",
    "        tt_arrival_times = stop_info['arrival_time_timetable']\n",
    "        real_arrival_times = stop_info['arrival_time_real']\n",
    "        real_stop_ids = stop_info['stop_id']\n",
    "        stop_dates = stop_info['date_str']\n",
    "        interpolated_status = stop_info['interpolated']\n",
    "       \n",
    "        real_timestamps = [convert_to_unix_timestamp(p, q) for p, q in zip (real_arrival_times, stop_dates)]\n",
    "        tt_timestamps = [convert_to_unix_timestamp(p, q) for p, q in zip (tt_arrival_times, stop_dates)]\n",
    "        # print(len(real_stop_ids), len(real_timestamps), len(tt_timestamps))\n",
    "        trips.append([[i, j, k, p] for i, j, k, p in zip(real_stop_ids, real_timestamps, tt_timestamps, interpolated_status)])\n",
    "        all_stop_ids.append(real_stop_ids)\n",
    "    \n",
    "    unique_shapes = get_unique_values_from_column(trips_on_this_route, 'shape_id')\n",
    "    line = dict()\n",
    "    for shape_id in unique_shapes:\n",
    "        try:\n",
    "            s = shape_dict[shape_id]\n",
    "            if shape_id not in line:\n",
    "                line[shape_id] = s['geometry']\n",
    "        except:\n",
    "            # print(f'Shape ID was {shape_id}, type {type(shape_id)}')\n",
    "            continue\n",
    "    \n",
    "    flat_stop_list = [v for j in all_stop_ids for v in j]\n",
    "    unique_stops = set(flat_stop_list)\n",
    "    stops = dict()\n",
    "    for s in unique_stops:\n",
    "        try:\n",
    "            b = int(stops_dict[s]['Bearing'])\n",
    "        except:\n",
    "            b = None\n",
    "        stops[s] = dict({\"name\": stops_dict[s]['stop_name'], \"lon\": stops_dict[s]['stop_lon'], \"lat\": stops_dict[s]['stop_lat'], \"bearing\": b})\n",
    "\n",
    "    if not human_route_id:\n",
    "        fname = f\"web/{rgncd}/{route_short_name}.json\"\n",
    "    else:\n",
    "        fname = f\"web/{rgncd}/{human_route_id}.json\"\n",
    "\n",
    "    if os.path.isfile(fname):\n",
    "        # msg = f'File already exists for {route_short_name, agency_name}. Appending to this file.\\n'\n",
    "        # with open(ROOT / f'web/{rgncd}/errors.txt', 'a') as f:\n",
    "        #     f.writelines(msg)\n",
    "        # print(f'File already exists for {route_short_name, agency_name}. Appending to this file.')\n",
    "        # Read the file.\n",
    "        with open(ROOT / fname, 'r') as f:\n",
    "            content = json.load(f)\n",
    "        old_trips = content['trips']\n",
    "        old_stops = content['stops']\n",
    "        # Append the trips to that file.\n",
    "        for t in trips:\n",
    "            old_trips.append(t)\n",
    "        content['trips'] = old_trips\n",
    "        # Merge the new stops in case some are only on one route. Uses | (OR) operator for dictionaries.\n",
    "        new_stops = old_stops | stops\n",
    "        content['stops'] = new_stops\n",
    "        # Write the file.\n",
    "        with open(ROOT / fname, \"w\") as f:\n",
    "            json.dump(content, f, separators=(',',':'))\n",
    "    else:\n",
    "        content = dict({'meta': meta, 'line': line, 'stops': stops, 'trips': trips})\n",
    "        with open(ROOT / fname, \"w\") as f:\n",
    "            json.dump(content, f, separators=(',',':'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bus-tracking-JZQiYmLK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
